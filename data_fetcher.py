import os
import sys
import requests
import pandas as pd
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ£€æµ‹è¿è¡Œç¯å¢ƒ
IS_GITHUB_ACTIONS = os.getenv('GITHUB_ACTIONS') == 'true'
IS_STREAMLIT = False

# å°è¯•å¯¼å…¥streamlitï¼Œå¦‚æœå¤±è´¥åˆ™åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿstå¯¹è±¡
try:
    import streamlit as st
    IS_STREAMLIT = True
except ImportError:
    # åˆ›å»ºè™šæ‹Ÿçš„streamlitå¯¹è±¡ç”¨äºéStreamlitç¯å¢ƒ
    class VirtualStreamlit:
        def spinner(self, text):
            if IS_GITHUB_ACTIONS:
                print(f"::group::{text}")
            else:
                print(f"ğŸ”„ {text}")
            return self
        def __enter__(self):
            return self
        def __exit__(self, *args):
            if IS_GITHUB_ACTIONS:
                print("::endgroup::")
        def progress(self, value):
            if IS_GITHUB_ACTIONS and hasattr(self, '_last_progress'):
                progress_pct = int(value * 100)
                if progress_pct != self._last_progress:
                    print(f"Progress: {progress_pct}%")
                    self._last_progress = progress_pct
            return self
        def success(self, text):
            if IS_GITHUB_ACTIONS:
                print(f"::notice title=Success::{text}")
            else:
                print(f"âœ… {text}")
        def error(self, text):
            if IS_GITHUB_ACTIONS:
                print(f"::error title=Error::{text}")
            else:
                print(f"âŒ {text}")
        def warning(self, text):
            if IS_GITHUB_ACTIONS:
                print(f"::warning title=Warning::{text}")
            else:
                print(f"âš ï¸ {text}")
    
    st = VirtualStreamlit()
    st._last_progress = -1

def fetch_ssq_data():
    """è·å–åŒè‰²çƒæ•°æ®"""
    # å®šä¹‰ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶å
    save_directory = "data"
    file_name = "ssq.csv"
    file_path = os.path.join(save_directory, file_name)
    
    # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    try:
        os.makedirs(save_directory, exist_ok=True)
        if IS_GITHUB_ACTIONS:
            # ç¡®ä¿ç›®å½•æƒé™æ­£ç¡®
            os.chmod(save_directory, 0o755)
    except Exception as e:
        logger.error(f"åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: {e}")
        if IS_STREAMLIT:
            st.error(f"åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: {e}")
        return None
    
    # å®šä¹‰æ•°æ®æºURL
    url = "https://data.17500.cn/ssq_asc.txt"
    
    try:
        # å‘é€HTTP GETè¯·æ±‚è·å–æ•°æ®
        with st.spinner('æ­£åœ¨è·å–æœ€æ–°åŒè‰²çƒæ•°æ®...'):
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = requests.get(url, headers=headers, timeout=30)
                    response.raise_for_status()
                    break
                except requests.RequestException as e:
                    if attempt == max_retries - 1:
                        raise e
                    logger.warning(f"è¯·æ±‚å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")
                    if IS_GITHUB_ACTIONS:
                        print(f"::warning::è¯·æ±‚å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {e}")
                    
    except requests.RequestException as e:
        error_msg = f"è¯·æ±‚æ•°æ®æ—¶å‡ºé”™: {e}"
        logger.error(error_msg)
        st.error(error_msg)
        return None
    
    data = []
    # å‡è®¾æ•°æ®æŒ‰Seqå‡åºæ’åˆ—
    lines = response.text.strip().split('\n')
    
    progress_bar = st.progress(0)
    total_lines = len(lines)
    
    for i, line in enumerate(lines):
        # æ›´æ–°è¿›åº¦æ¡
        if IS_STREAMLIT:
            progress_bar.progress((i + 1) / total_lines)
        elif IS_GITHUB_ACTIONS and i % 5000 == 0:  # GitHub Actions: æ¯5000è¡Œæ‰“å°ä¸€æ¬¡
            progress_pct = int((i + 1) / total_lines * 100)
            print(f"::notice::æ•°æ®å¤„ç†è¿›åº¦: {progress_pct}% ({i+1}/{total_lines})")
        elif not IS_STREAMLIT and i % 1000 == 0:  # æœ¬åœ°è¿è¡Œ: æ¯1000è¡Œæ‰“å°ä¸€æ¬¡
            print(f"å¤„ç†è¿›åº¦: {i+1}/{total_lines} ({(i+1)/total_lines*100:.1f}%)")
        
        if len(line) < 10:
            continue  # è·³è¿‡æ— æ•ˆè¡Œ
        
        # ä»…åˆ†å‰²ç¬¬ä¸€ä¸ªé€—å·ï¼Œå¿½ç•¥åç»­æ•°æ®
        parts = line.split(',', 1)
        if not parts:
            continue  # è·³è¿‡ç©ºè¡Œ
        
        first_part = parts[0].strip()
        fields = first_part.split()
        
        # ç¡®ä¿æœ‰è‡³å°‘ 8 ä¸ªå­—æ®µï¼ˆSeq + æ—¥æœŸ + 6ä¸ªçº¢çƒ + 1ä¸ªè“çƒï¼‰
        if len(fields) < 8:
            continue
        
        seq = fields[0]
        red_balls = fields[2:8]  # æå–6ä¸ªçº¢çƒ
        blue_ball = fields[8] if len(fields) > 8 else None  # æå–è“çƒ
        
        # æ£€æŸ¥çº¢çƒå’Œè“çƒæ•°é‡æ˜¯å¦æ­£ç¡®
        if len(red_balls) != 6 or not blue_ball:
            continue
        
        # æ„å»ºæ•°æ®å­—å…¸
        item = {'Seq': seq}
        for i in range(1, 7):
            item[f'red_{i}'] = red_balls[i-1]
        item['blue'] = blue_ball
        
        data.append(item)
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data, columns=['Seq'] + [f'red_{i}' for i in range(1, 7)] + ['blue'])
    
    if df.empty:
        st.error("æ²¡æœ‰æå–åˆ°ä»»ä½•æ•°æ®ã€‚è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–æ•°æ®æºæ˜¯å¦å¯ç”¨ã€‚")
        return None
    else:
        # å°†Seqè½¬æ¢ä¸ºæ•´æ•°ä»¥ä¾¿æ’åº
        try:
            df['Seq'] = df['Seq'].astype(int)
        except ValueError as e:
            st.error(f"è½¬æ¢Seqä¸ºæ•´æ•°æ—¶å‡ºé”™: {e}")
            return None
        
        # æŒ‰Seqå‡åºæ’åº
        df.sort_values(by='Seq', inplace=True)
        
        try:
            # ä¿å­˜ä¸ºCSVæ–‡ä»¶
            df.to_csv(file_path, encoding="utf-8", index=False)
            
            # éªŒè¯æ–‡ä»¶æ˜¯å¦ä¿å­˜æˆåŠŸ
            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                success_msg = f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {file_path}ï¼Œå…±è·å– {len(df)} æœŸæ•°æ®"
                logger.info(success_msg)
                st.success(success_msg)
                
                if IS_GITHUB_ACTIONS:
                    print(f"::notice title=æ•°æ®è·å–æˆåŠŸ::å…±è·å– {len(df)} æœŸæ•°æ®")
                
                return df
            else:
                raise Exception("æ–‡ä»¶ä¿å­˜å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
                
        except Exception as e:
            error_msg = f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}"
            logger.error(error_msg)
            st.error(error_msg)
            return None

def load_local_data():
    """åŠ è½½æœ¬åœ°æ•°æ®"""
    file_path = os.path.join("data", "ssq.csv")
    if os.path.exists(file_path):
        try:
            df = pd.read_csv(file_path)
            return df
        except Exception as e:
            st.error(f"åŠ è½½æœ¬åœ°æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    else:
        return None

def get_latest_period_from_web():
    """ä»ç½‘ç»œè·å–æœ€æ–°æœŸæ•°"""
    url = "https://data.17500.cn/ssq_asc.txt"
    try:
        response = requests.get(url, headers={'User-agent': 'chrome'})
        response.raise_for_status()
        lines = response.text.strip().split('\n')
        
        # è·å–æœ€åä¸€è¡Œæœ‰æ•ˆæ•°æ®
        for line in reversed(lines):
            if len(line) > 10:
                fields = line.split()
                if len(fields) >= 8:
                    return int(fields[0])
        return None
    except:
        return None